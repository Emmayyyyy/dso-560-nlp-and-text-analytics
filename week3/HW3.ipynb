{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3\n",
    "\n",
    "Submit via Slack. Due on Monday, April 13th, 2020, 11:59pm PST. You may work with one other person.\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "You are an analyst working at Amazon as a product analyst, and charged with identifying areas for improvement to the Amazon toy product lines, which have been suffering recently from lower reviews.\n",
    "\n",
    "Using the **`poor_amazon_toy_reviews.txt`** and **`good_amazon_toy_reviews.txt`** datasets, clean and parse the text reviews. Explain the decisions you make:\n",
    "- why remove/keep stopwords?\n",
    "- stemming versus lemmatization?\n",
    "- regex cleaning and substitution?\n",
    "- adding in custom stopwords?\n",
    "- what `n` for your `n-grams`?\n",
    "- which words to collocate together?\n",
    "\n",
    "Finally, generate a TF-IDF report that **visualizes**:\n",
    "* the features your analysis showed that customers cited as reasons for a 5 star review\n",
    "* the most common issues identified from your analysis that generated customer dissatisfaction.\n",
    "\n",
    "Explain to what degree the TF-IDF findings make sense - what are its limitations?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_file = open(\"/Users/yanboyang/Desktop/USC/20Spring/dso-560-nlp-and-text-analytics/week1/good_amazon_toy_reviews.txt\", \"r\")\n",
    "good_file.readline()\n",
    "poor_file = open(\"/Users/yanboyang/Desktop/USC/20Spring/dso-560-nlp-and-text-analytics/week1/poor_amazon_toy_reviews.txt\", \"r\")\n",
    "poor_file.readline()\n",
    "good = list(map(lambda review: review.replace('\\n', '').replace('\\\\\\\\', '').replace('/',''), good_file))[:10000]\n",
    "poor = list(map(lambda review: review.replace('\\n', '').replace('\\\\\\\\', '').replace('/',''), poor_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english') + ['actually','usually','oh','always','thing','really','probably']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,3),\n",
    "                             token_pattern=r'\\b[a-zA-Z0-9]{2,}\\b',\n",
    "                             max_df=0.5, stop_words=sw)\n",
    "X_good = vectorizer.fit_transform(good)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X_good.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score[\"word\"] = terms\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year old</th>\n",
       "      <td>64.871441</td>\n",
       "      <td>year old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daughter loves</th>\n",
       "      <td>54.891959</td>\n",
       "      <td>daughter loves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great product</th>\n",
       "      <td>52.868135</td>\n",
       "      <td>great product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kids love</th>\n",
       "      <td>51.740721</td>\n",
       "      <td>kids love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>son loves</th>\n",
       "      <td>51.696421</td>\n",
       "      <td>son loves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    score            term\n",
       "year old        64.871441        year old\n",
       "daughter loves  54.891959  daughter loves\n",
       "great product   52.868135   great product\n",
       "kids love       51.740721       kids love\n",
       "son loves       51.696421       son loves"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import string\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "result = []\n",
    "for t in good:\n",
    "    words = word_tokenize(t)\n",
    "    final = []\n",
    "    for w in words:\n",
    "        final.append(lemmatizer.lemmatize(w).strip(string.punctuation))\n",
    "    res = \" \".join(final)\n",
    "    result.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(sw + [\".\",'.', \",\",\":\", \"''\", \"'s\", \"'\", \"``\", \"(\", \")\", \"-\",\" \",\"\"])\n",
    "new_documents = []\n",
    "for review in result:\n",
    "    new_document = []\n",
    "    for word in review.split(' '):\n",
    "        if word.strip().lower() not in stopwords:\n",
    "            new_document.append(word)\n",
    "    new_documents.append(new_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('br', 'br'),\n",
       " ('year', 'old'),\n",
       " ('daughter', 'love'),\n",
       " ('son', 'love'),\n",
       " ('ca', \"n't\"),\n",
       " ('well', 'made'),\n",
       " ('doe', \"n't\"),\n",
       " ('kid', 'love'),\n",
       " ('put', 'together'),\n",
       " ('Great', 'product'),\n",
       " ('old', 'love'),\n",
       " ('3', 'year'),\n",
       " ('grandson', 'love'),\n",
       " ('month', 'old'),\n",
       " ('old', 'grandson'),\n",
       " ('wa', 'great'),\n",
       " ('lot', 'fun'),\n",
       " ('4', 'year'),\n",
       " ('absolutely', 'love'),\n",
       " ('granddaughter', 'love'),\n",
       " ('wa', 'perfect'),\n",
       " ('much', 'fun'),\n",
       " ('2', 'year'),\n",
       " ('highly', 'recommend'),\n",
       " ('look', 'like')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "\n",
    "collocation_finder = BigramCollocationFinder.from_documents(new_documents)\n",
    "measures = BigramAssocMeasures()\n",
    "\n",
    "collocation_finder.nbest(measures.raw_freq, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,3),\n",
    "                             token_pattern=r'\\b[a-zA-Z0-9]{2,}\\b',\n",
    "                             max_df=0.5, stop_words=stopwords)\n",
    "X_good = vectorizer.fit_transform(result)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X_good.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score[\"word\"] = terms\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year old</th>\n",
       "      <td>69.715294</td>\n",
       "      <td>year old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daughter love</th>\n",
       "      <td>59.568567</td>\n",
       "      <td>daughter love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>son love</th>\n",
       "      <td>54.062531</td>\n",
       "      <td>son love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great product</th>\n",
       "      <td>52.949429</td>\n",
       "      <td>great product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grandson love</th>\n",
       "      <td>49.349970</td>\n",
       "      <td>grandson love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kid love</th>\n",
       "      <td>45.690448</td>\n",
       "      <td>kid love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granddaughter love</th>\n",
       "      <td>39.267746</td>\n",
       "      <td>granddaughter love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well made</th>\n",
       "      <td>29.587302</td>\n",
       "      <td>well made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granddaughter loved</th>\n",
       "      <td>29.002483</td>\n",
       "      <td>granddaughter loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent product</th>\n",
       "      <td>28.502335</td>\n",
       "      <td>excellent product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>br br</th>\n",
       "      <td>28.241783</td>\n",
       "      <td>br br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grandson loved</th>\n",
       "      <td>27.780543</td>\n",
       "      <td>grandson loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great price</th>\n",
       "      <td>26.958448</td>\n",
       "      <td>great price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great game</th>\n",
       "      <td>26.851165</td>\n",
       "      <td>great game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great quality</th>\n",
       "      <td>25.873575</td>\n",
       "      <td>great quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good quality</th>\n",
       "      <td>24.752191</td>\n",
       "      <td>good quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrived time</th>\n",
       "      <td>22.979221</td>\n",
       "      <td>arrived time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun game</th>\n",
       "      <td>22.464988</td>\n",
       "      <td>fun game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kid loved</th>\n",
       "      <td>22.311907</td>\n",
       "      <td>kid loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>son loved</th>\n",
       "      <td>21.351525</td>\n",
       "      <td>son loved</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         score                 word\n",
       "year old             69.715294             year old\n",
       "daughter love        59.568567        daughter love\n",
       "son love             54.062531             son love\n",
       "great product        52.949429        great product\n",
       "grandson love        49.349970        grandson love\n",
       "kid love             45.690448             kid love\n",
       "granddaughter love   39.267746   granddaughter love\n",
       "well made            29.587302            well made\n",
       "granddaughter loved  29.002483  granddaughter loved\n",
       "excellent product    28.502335    excellent product\n",
       "br br                28.241783                br br\n",
       "grandson loved       27.780543       grandson loved\n",
       "great price          26.958448          great price\n",
       "great game           26.851165           great game\n",
       "great quality        25.873575        great quality\n",
       "good quality         24.752191         good quality\n",
       "arrived time         22.979221         arrived time\n",
       "fun game             22.464988             fun game\n",
       "kid loved            22.311907            kid loved\n",
       "son loved            21.351525            son loved"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Attribution (Feature Engineering and Regex Practice)\n",
    "\n",
    "Download the [dataset](https://dso-560-nlp-text-analytics.s3.amazonaws.com/truncated_catalog.csv) from the class S3 bucket (`dso560-nlp-text-analytics`).\n",
    "\n",
    "In preparation for the group project, our client company has provided a dataset of women's clothing products they are considering cataloging. \n",
    "\n",
    "1. Filter for only **women's clothing items**.\n",
    "\n",
    "2. For each clothing item:\n",
    "\n",
    "* Identify its **category**:\n",
    "```\n",
    "Bottom\n",
    "One Piece\n",
    "Shoe\n",
    "Handbag\n",
    "Scarf\n",
    "```\n",
    "* Identify its **color**:\n",
    "```\n",
    "Beige\n",
    "Black\n",
    "Blue\n",
    "Brown\n",
    "Burgundy\n",
    "Gold\n",
    "Gray\n",
    "Green\n",
    "Multi \n",
    "Navy\n",
    "Neutral\n",
    "Orange\n",
    "Pinks\n",
    "Purple\n",
    "Red\n",
    "Silver\n",
    "Teal\n",
    "White\n",
    "Yellow\n",
    "```\n",
    "\n",
    "Your output will be the same dataset, except with **3 additional fields**:\n",
    "* `is_womens_clothing`\n",
    "* `product_category`\n",
    "* `colors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
